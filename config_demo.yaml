server_name: 0.0.0.0

# Model loading options
default_load_in_8bit: false
default_torch_dtype: float16

# UI Settings
ui_show_starter_tooltips: false
ui_inference_open_options_by_default: false
ui_chat_reminder_message: "Language models may produce inaccurate information about people, places, or facts."
ui_features:
  - chat
  - inference
  - tools

# UI Customization
ui_title: TWLM Demo
# ui_emoji: 🦙🎛️
ui_subtitle: 'Taiwanese Mandarin LLM Project: https://github.com/zetavg/twlm'
# ui_show_sys_info: true

default_generation_config:
  temperature: 1
  top_k: 40
  top_p: 0.2
  num_beams: 3
  repetition_penalty: 2.4
  max_new_tokens: 800
default_generation_stop_sequence: '### Human:'

# Special Modes
demo_mode: true
# ui_dev_mode: true
