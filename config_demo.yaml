server_name: 0.0.0.0

# Model loading options
default_load_in_8bit: false
default_torch_dtype: float16

# UI Settings
ui_show_starter_tooltips: false
ui_inference_open_options_by_default: false
ui_chat_reminder_message: "Language models may produce inaccurate information about people, places, or facts. <br/>因訓練成本限制，模型目前對長串對話的表現不是很好，在多輪對話後可能會開始回應重複的內容。如果對回應不滿意，可以嘗試按下「Regenerate Response」。對話紀錄只會保存在瀏覽器中，若有需要請自行備份 (展開左下角「Raw Data」查看相關資訊)。下方 \"Examples\" 有一些訊息範本可以選擇。"
ui_features:
  - chat
  - inference
  - tools

# UI Customization
ui_title: TWLM Demo
# ui_emoji: 🦙🎛️
ui_subtitle: 'Taiwanese Mandarin LLM Project: [https://github.com/zetavg/twlm](https://github.com/zetavg/twlm)'
# ui_show_sys_info: true

default_generation_config:
  temperature: 1
  top_k: 40
  top_p: 0.4
  num_beams: 3
  repetition_penalty: 2.4
  max_new_tokens: 800
default_generation_stop_sequence: '### Human:'

# Special Modes
demo_mode: true
# ui_dev_mode: true
